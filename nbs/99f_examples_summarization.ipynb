{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from onprem.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pipelines` modules includes the `Summarizer` to summarize one or more documents with an LLM.  This notebook shows a couple of examples.\n",
    "\n",
    "The `Summarizer` runs multiple intermediate prompts and inferences, so we will set `verbose-False` and `mute_stream=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "from onprem import LLM\n",
    "from onprem.pipelines import Summarizer\n",
    "llm = LLM(n_gpu_layers=35, verbose=False, mute_stream=True) # set based on your system\n",
    "summarizer = Summarizer(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's download the [ktrain paper](https://www.jmlr.org/papers/volume23/21-1124/21-1124.pdf) and summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | notest\n",
    "!wget --user-agent=\"Mozilla\" https://arxiv.org/pdf/2004.10703.pdf -O /tmp/ktrain.pdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ktrain is an open-source Python library that provides a range of tools for building and deploying machine learning models, with a focus on text classification tasks. The library automates parts of the machine learning workflow and allows domain experts to use their expertise to make choices that best fit their unique application requirements. The unified interface enables quick solution of a wide range of tasks in as little as three or four lines of code, making machine learning more accessible and easier to apply by both beginners and experienced practitioners.\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "text = summarizer.summarize('/tmp/ktrain.pdf', max_chunks_to_use=5)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For faster summarizations, we set `max_chunks_to_use=5`, so that only the first five chunks of 1000 characters are considered (where `chunk_size=1000` is set as the default). You can set `max_chunks_to_use` to `None` (or omit the parameter) to consider the entire document when generating the summarization, as shown in the next example.\n",
    "\n",
    "Next, let's download an example blog post about LLMs and summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This set of documents provides an overview of different approaches for planning and self-reflection in LLM-powered autonomous agent systems, along with practical guidance on how to develop and optimize LLM-based agents for various tasks. The challenges and limitations of using LLMs in language learning and natural language interfaces for agents are also discussed, as well as related research and resources for developing effective prompting techniques and efficient RL algorithms.\n"
     ]
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "with open('/tmp/blog.txt', 'w') as f:\n",
    "    f.write(docs[0].page_content)\n",
    "\n",
    "text = summarizer.summarize('/tmp/blog.txt') # this takes longer as it looks at ever piece of text in the blog post\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a need, you can experiment with different parameters, as described in [our documentation](https://amaiya.github.io/onprem/utils.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
